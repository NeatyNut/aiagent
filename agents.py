from system_prompt import *
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
from state import AgentState
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.graph import add_messages
from tools import init_plan
import os

class PlannerAgent:
    def __init__(self):
        load_dotenv()
        self.name = "planner"
        self.description = "ì‚¬ìš©ì ëª©í‘œë¥¼ ë¶„ì„í•´ ë…¼ë¦¬ì  ìˆœì„œë¡œ êµ¬ì„±ëœ ë‹¨ê³„ë³„ ì‘ì—…ì„ ì„¤ê³„í•©ë‹ˆë‹¤."
        self.instructions = INSTRUCTIONS[self.name]
        self.llm = ChatGoogleGenerativeAI(model=os.getenv("MODEL", "gemini-3-flash-preview"), temperature=0)
        # self.llm.bind_tools([init_plan])

    def generate(self, state: AgentState):
        # 1. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (í…ŒìŠ¤íŠ¸ìš©)
        user_input = input(f'ğŸ˜’ì‹œí‚¤ì‹¤ ì—…ë¬´ ì…ë ¥ >>> ')
        
        # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë° ë©”ì‹œì§€ ì„¤ì •
        # system_prompt = make_system_prompt(self.name, self.description, self.instructions)
        messages = [HumanMessage(content=user_input)]
        
        # 3. LLM í˜¸ì¶œ (bind_tools ì‚¬ìš© ê¶Œì¥)
        # self.llm = ChatGoogleGenerativeAI(...).bind_tools([init_plan])
        aimessage = self.llm.invoke(messages)
        print(aimessage)
        
        # 4. Tool Callì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¤í–‰í•˜ê¸°
        updates = {"messages": [aimessage]} # ë©”ì‹œì§€ ê¸°ë¡ ì—…ë°ì´íŠ¸ ì¤€ë¹„
        
        if aimessage.tool_calls:
            for tool_call in aimessage.tool_calls:
                if tool_call["name"] == "init_plan":
                    # íˆ´ ì‹¤í–‰ (argsì—ëŠ” LLMì´ ì¶”ì¶œí•œ 'tasks' ë¦¬ìŠ¤íŠ¸ê°€ ë“¤ì–´ìˆìŒ)
                    # init_planì€ dict[int, tuple]ë¥¼ ë°˜í™˜í•¨
                    tasks_result = init_plan.invoke(tool_call["args"])
                    updates["tasks"] = tasks_result  # ğŸ‘ˆ í•µì‹¬: state["tasks"]ì— ë‹´ê¸°ë„ë¡ ë°˜í™˜
                    
        return updates # ìˆ˜ì •ëœ ë¶€ë¶„ë§Œ ë°˜í™˜í•˜ë©´ LangGraphê°€ ì•Œì•„ì„œ mergeí•©ë‹ˆë‹¤.